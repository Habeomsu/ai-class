1주차 딥러닝 (readme)
1.	값을 예측, 물체 인지, 음성 인식, 이미지 인식, 객체 인식 등(분류 , 회귀, 인식)

2.	지도 학습: 정답이 있는 것 
반지도 학습 : 정답이 없는 것과 있는 것을 섞음
강화 학습 : 보상을 통해 학습을 진해

3.	전통적인 프로그램과 인공지능의 차이점 : 프로그래머가 규칙을 준다. ai는 input, output 을 가지고 규칙을 찾는다.

4.	딥러닝 : 모델 안에서 특징 추출과 학습을 같이 진행
머신 러닝 : 특징을 추출해서 입력
5.	분류 : 범주로 분류
회귀 : 연속적인 값을 가지고 다음 값을 예측

6.	차원의 저주: 차원이 증가할 수록 데이터 분석의 효율이 떨어짐 – feature를 줄인다.  L1,L2 규제 

7.	너무 많은 차원은 분석의 효율이 떨어지기 때문에 

8.	Ridge 와 lasso의 차이점 

9.	오버피팅 : 과도하게 학습된 것, 노이즈 ,아웃 라이너, 등등 잘못된 데이터도 학습되는 현상 – 모델을 단순하게 만든다, 규제

언더피팅 : 데이터 파악이 잘 안 된것 – 데이터 추가 
	
10.	특성 엔지니어링과 특성 선택
11.	전처리 : 데이터를 더욱 효율적으로 학습 시키기 위해서 
12.	EDA

13.	신경망 – Loss, optimizer, 역전파, 순전파, activation function, one-hotencodeing

원핫 인코딩 – 컴퓨터는 0,1 사이의 값을 인식 
역전파 – 계산을 앞으로 이어 나가서 손실을 구함 
순전파 – 구한 값과 정답의 차이를 가지고 다시 bias와 weight 를 구함
활성화 함수 - 특징 추출을 비선형성을 추가해서 계산을 더 잘하게 하기 위해
옵티마이저 - 최적화 : adam, 
경사하강법 - 기울기가 (weight) 0 인 값을 찾는 과정 최적화된 가중치를 갖기 
