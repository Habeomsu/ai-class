인공지능과 딥러닝의 차이 : ai - 굉장히 많은 알고리즘을 포함 ( 유전자 알고리즘, 
                    딥러닝 - 입력과 출력을 가지고 규칙을 찾는다 - 데이터의 특성을 얻는다,(bias, weight)
                        - 새로운 f(x)를 구할 수 있다

노이즈를 추가하면 결국엔 같아진다 - 반대로 노이즈로 부터 각각의 사진을 만들 수 있다 !!!!
차원을 줄이는 이유 - f(x) 를 쉽게 구하기 위해
latent variable -  통계 및 머신러닝에서 직접 관찰할 수 없는 변수를 의미합니다 
latent space  - 딥러닝이나 머신러닝에서 데이터의 내재된 구조를 나타내는 공간입니다

머신 러닝 종류 - 3가지 
지도 학습, 비지도 학습, 강화 학습(보상을 주고)
unsupervisor 사용 이유 - lable 작업은 시간과 비용이 많이 든다
reignforce - gpt, llm 등 

데이터 품질이 낮은 이유 ? - 노이즈, 이상치(아웃 라이어)
 
오버피팅 - 이상치, 노이즈 까지 학습 - 규제 (norm1 , norm2)
언더피팅 - 데이터가 부족해서 생김

크로스 밸리데이션(Cross-Validation)은 머신러닝에서 모델의 성능을 평가하기 위해 데이터를 여러 번 나누어 학습과 테스트를 반복하는 기법입니다. 주된 목적은 모델이 새로운 데이터에 대해 얼마나 잘 일반화하는지를 평가하는 것입니다. 데이터셋이 충분히 크지 않을 때 모델의 성능을 신뢰할 수 있게만들기 위해 사용됩니다.
데이터의 분포가 균일 하지 않아서 사용

트레인과 테스트로 나눈다

성능 지표 : 정확도, 손실, 

하이퍼 파라미터: 모델에 들어가는 변수들 (loss, node , softmax, metrics,batch,epoce,learning late) 

precision  : 정밀도
recall     : 실제로 정답인 것 중에서 정답이라고 예측한 비율
f1-score   : 정밀도와 재현율의 조화 평균(Harmonic Mean) - 데이터가 불균형 일때 accuracy는 잘 못 구함 
support    : 실제 샘플의 개수
p - 153 참고

경사 하강법 -기울기를 구하는 과정

로지스틱 회귀 - weight, bias 구하는 과정 
svm  - super vector machine - 경계선에서 멀리 만드는 것
decision tree - 20고개 , 불순도? - 불순도를 높이도록 만드는 것 
ramdom forest - 여러개의 decision tree 가 모인 것 
앙상블 - 이런거 저런거 섞어 쓰는 것 (모델을 섞어 쓰는 것) 

regression - 상관관계 비교 

스태킹 - 블랜딩? - 원두 섞기 합치기

차원 축소 - f(x)를 쉽게 구하기 위해서 

pca - 차원을 줄이기 위해서 주 성분을 요약



